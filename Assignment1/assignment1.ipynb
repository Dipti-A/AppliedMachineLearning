{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: A classification example: fetal heart condition diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>e</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>DR</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>E</th>\n",
       "      <th>AD</th>\n",
       "      <th>DE</th>\n",
       "      <th>LD</th>\n",
       "      <th>FS</th>\n",
       "      <th>SUSP</th>\n",
       "      <th>Unnamed: 42</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>Unnamed: 44</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>411.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>533.0</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       b       e   AC   FM   UC   DL   DS   DP   DR  Unnamed: 9  ...    E  \\\n",
       "0  240.0   357.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         NaN  ... -1.0   \n",
       "1    5.0   632.0  4.0  0.0  4.0  2.0  0.0  0.0  0.0         NaN  ... -1.0   \n",
       "2  177.0   779.0  2.0  0.0  5.0  2.0  0.0  0.0  0.0         NaN  ... -1.0   \n",
       "3  411.0  1192.0  2.0  0.0  6.0  2.0  0.0  0.0  0.0         NaN  ... -1.0   \n",
       "4  533.0  1147.0  4.0  0.0  5.0  0.0  0.0  0.0  0.0         NaN  ... -1.0   \n",
       "\n",
       "    AD   DE   LD   FS  SUSP  Unnamed: 42  CLASS  Unnamed: 44  NSP  \n",
       "0 -1.0 -1.0 -1.0  1.0  -1.0          NaN    9.0          NaN  2.0  \n",
       "1  1.0 -1.0 -1.0 -1.0  -1.0          NaN    6.0          NaN  1.0  \n",
       "2  1.0 -1.0 -1.0 -1.0  -1.0          NaN    6.0          NaN  1.0  \n",
       "3  1.0 -1.0 -1.0 -1.0  -1.0          NaN    6.0          NaN  1.0  \n",
       "4 -1.0 -1.0 -1.0 -1.0  -1.0          NaN    2.0          NaN  1.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file.\n",
    "data = pd.read_csv(\"CTG.csv\", skiprows=1)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...   Min    Max  \\\n",
       "0  120.0  0.0  0.0  0.0  0.0  0.0  0.0  73.0   0.5  43.0  ...  62.0  126.0   \n",
       "1  132.0  4.0  0.0  4.0  2.0  0.0  0.0  17.0   2.1   0.0  ...  68.0  198.0   \n",
       "2  133.0  2.0  0.0  5.0  2.0  0.0  0.0  16.0   2.1   0.0  ...  68.0  198.0   \n",
       "3  134.0  2.0  0.0  6.0  2.0  0.0  0.0  16.0   2.4   0.0  ...  53.0  170.0   \n",
       "4  132.0  4.0  0.0  5.0  0.0  0.0  0.0  16.0   2.4   0.0  ...  53.0  170.0   \n",
       "\n",
       "   Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  NSP  \n",
       "0   2.0     0.0  120.0  137.0   121.0      73.0       1.0  2.0  \n",
       "1   6.0     1.0  141.0  136.0   140.0      12.0       0.0  1.0  \n",
       "2   5.0     1.0  141.0  135.0   138.0      13.0       0.0  1.0  \n",
       "3  11.0     0.0  137.0  134.0   137.0      13.0       1.0  1.0  \n",
       "4   9.0     0.0  137.0  136.0   138.0      11.0       1.0  1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the relevant numerical columns.\n",
    "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
    "                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
    "                 'Median', 'Variance', 'Tendency', 'NSP']\n",
    "data = data[selected_cols].dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>134.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>132.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...    Min  \\\n",
       "658   130.0  1.0  0.0  3.0  0.0  0.0  0.0  24.0   1.2  12.0  ...  120.0   \n",
       "1734  134.0  9.0  1.0  8.0  5.0  0.0  0.0  59.0   1.2   0.0  ...   80.0   \n",
       "1226  125.0  1.0  0.0  4.0  0.0  0.0  0.0  43.0   0.7  31.0  ...  120.0   \n",
       "1808  143.0  0.0  0.0  1.0  0.0  0.0  0.0  69.0   0.3   6.0  ...  132.0   \n",
       "825   152.0  0.0  0.0  4.0  0.0  0.0  0.0  62.0   0.4  59.0  ...  136.0   \n",
       "\n",
       "        Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  NSP  \n",
       "658   155.0   1.0     0.0  134.0  133.0   135.0       1.0       0.0  1.0  \n",
       "1734  189.0   6.0     0.0  150.0  146.0   150.0      33.0       0.0  1.0  \n",
       "1226  141.0   0.0     0.0  131.0  130.0   132.0       1.0       0.0  1.0  \n",
       "1808  159.0   1.0     0.0  145.0  144.0   146.0       1.0       0.0  1.0  \n",
       "825   161.0   0.0     0.0  159.0  156.0   158.0       1.0       1.0  2.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the dataset.\n",
    "data_shuffled = data.sample(frac=1.0, random_state=0)\n",
    "data_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658      normal\n",
       "1734     normal\n",
       "1226     normal\n",
       "1808     normal\n",
       "825     suspect\n",
       "Name: NSP, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into input part X and output part Y.\n",
    "X = data_shuffled.drop('NSP', axis=1)\n",
    "\n",
    "# Map the diagnosis code to a human-readable label.\n",
    "def to_label(y):\n",
    "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n",
    "\n",
    "Y = data_shuffled['NSP'].apply(to_label)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700, 426)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Partition the data into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "len(Xtrain), len(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Training the baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78235294, 0.78235294, 0.77941176, 0.77941176, 0.77941176])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "cross_val_score(clf, Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Trying out some different classifiers\n",
    "### a. Testing Tree-based classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91470588, 0.92941176, 0.91470588, 0.90588235, 0.94705882])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree classifier\n",
    "model= tree.DecisionTreeClassifier()\n",
    "\n",
    "# Calculating the score for training data\n",
    "cross_val_score(model, Xtrain, Ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93823529, 0.95      , 0.92941176, 0.93529412, 0.93823529])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest classifier\n",
    "model1= RandomForestClassifier()\n",
    "\n",
    "# Calculating the score for training data\n",
    "cross_val_score(model1, Xtrain, Ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94117647, 0.96176471, 0.94705882, 0.94411765, 0.95294118])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "model2= GradientBoostingClassifier()\n",
    "model2.fit(Xtrain,Ytrain)\n",
    "\n",
    "# Calculating the score for training data\n",
    "cross_val_score(model2, Xtrain, Ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Testing Linear classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84705882, 0.88529412, 0.82941176, 0.85294118, 0.71176471])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "model3= Perceptron()\n",
    "\n",
    "# Calculating the score for training data\n",
    "cross_val_score(model3, Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aswals\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\aswals\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\aswals\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\aswals\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\aswals\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.88823529, 0.88235294, 0.87058824, 0.87352941, 0.85588235])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "model4= LogisticRegression()\n",
    "\n",
    "# Calculating the score for training data\n",
    "cross_val_score(model4, Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aswals\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\aswals\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\aswals\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\aswals\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\aswals\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87647059, 0.84705882, 0.82941176, 0.85588235, 0.68235294])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "model5= LinearSVC()\n",
    "\n",
    "# Calculating the score for training data\n",
    "cross_val_score(model5, Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Testing Neural Network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85588235, 0.89705882, 0.85      , 0.87941176, 0.91764706])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP classifier\n",
    "model6= MLPClassifier()\n",
    "\n",
    "# Calculating the score for training data\n",
    "cross_val_score(model6, Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation :  \n",
    "\n",
    "### Gradient Boosting Classifier gave the highest score with cross validation.\n",
    "\n",
    "Gradient Boosting classifier is a classification algorithm that uses weak model to create a strong predictive model. This learning happens by optimizing the loss function.\n",
    "\n",
    "In this approach, we first create a base model which returns the most frequent value in case of classification and average value in case of regression. Once we calculate the output or predicted values from base model we further calculate the residuals (actuals - predicted target values). Now we create another model (using decision tree with its maximum depth) which takes residuals calculated earlier as target.\n",
    "\n",
    "We now have new predicted and residual values so now we calculate new predicted target values.\n",
    "\n",
    "This process will go on and we will see that the errors or residuals keep on reducing with every iteration.\n",
    "\n",
    "### This gives the highest accuracy score of ~ 93% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9295774647887324\n"
     ]
    }
   ],
   "source": [
    "# Using Gradient Boosting Classifier\n",
    "model2.fit(Xtrain, Ytrain)\n",
    "Yguess = model2.predict(Xtest)\n",
    "print(accuracy_score(Ytest, Yguess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Decision trees for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeLeaf:\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    # This method computes the prediction for this leaf node. This will just return a constant value.\n",
    "    def predict(self, x):\n",
    "        return self.value\n",
    "\n",
    "    # Utility function to draw a tree visually using graphviz.\n",
    "    def draw_tree(self, graph, node_counter, names):\n",
    "        node_id = str(node_counter)\n",
    "        val_str = f'{self.value:.4g}' if isinstance(self.value, float) else str(self.value)\n",
    "        graph.node(node_id, val_str, style='filled')\n",
    "        return node_counter+1, node_id\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, DecisionTreeLeaf):\n",
    "            return self.value == other.value\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeBranch:\n",
    "\n",
    "    def __init__(self, feature, threshold, low_subtree, high_subtree):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.low_subtree = low_subtree\n",
    "        self.high_subtree = high_subtree\n",
    "\n",
    "    # For a branch node, we compute the prediction by first considering the feature, and then \n",
    "    # calling the upper or lower subtree, depending on whether the feature is or isn't greater\n",
    "    # than the threshold.\n",
    "    def predict(self, x):\n",
    "        if x[self.feature] <= self.threshold:\n",
    "            return self.low_subtree.predict(x)\n",
    "        else:\n",
    "            return self.high_subtree.predict(x)\n",
    "\n",
    "    # Utility function to draw a tree visually using graphviz.\n",
    "    def draw_tree(self, graph, node_counter, names):\n",
    "        node_counter, low_id = self.low_subtree.draw_tree(graph, node_counter, names)\n",
    "        node_counter, high_id = self.high_subtree.draw_tree(graph, node_counter, names)\n",
    "        node_id = str(node_counter)\n",
    "        fname = f'F{self.feature}' if names is None else names[self.feature]\n",
    "        lbl = f'{fname} > {self.threshold:.4g}?'\n",
    "        graph.node(node_id, lbl, shape='box', fillcolor='yellow', style='filled, rounded')\n",
    "        graph.edge(node_id, low_id, 'False')\n",
    "        graph.edge(node_id, high_id, 'True')\n",
    "        return node_counter+1, node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DecisionTree(ABC, BaseEstimator):\n",
    "\n",
    "    def __init__(self, max_depth):\n",
    "        super().__init__()\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    # As usual in scikit-learn, the training method is called *fit*. We first process the dataset so that\n",
    "    # we're sure that it's represented as a NumPy matrix. Then we call the recursive tree-building method\n",
    "    # called make_tree (see below).\n",
    "    def fit(self, X, Y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.names = X.columns\n",
    "            X = X.to_numpy()\n",
    "        elif isinstance(X, list):\n",
    "            self.names = None\n",
    "            X = np.array(X)\n",
    "        else:\n",
    "            self.names = None\n",
    "        Y = np.array(Y)        \n",
    "        self.root = self.make_tree(X, Y, self.max_depth)\n",
    "        \n",
    "    def draw_tree(self):\n",
    "        graph = Digraph()\n",
    "        self.root.draw_tree(graph, 0, self.names)\n",
    "        return graph\n",
    "    \n",
    "    # By scikit-learn convention, the method *predict* computes the classification or regression output\n",
    "    # for a set of instances.\n",
    "    # To implement it, we call a separate method that carries out the prediction for one instance.\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        return [self.predict_one(x) for x in X]\n",
    "\n",
    "    # Predicting the output for one instance.\n",
    "    def predict_one(self, x):\n",
    "        return self.root.predict(x)        \n",
    "\n",
    "    # This is the recursive training \n",
    "    def make_tree(self, X, Y, max_depth):\n",
    "\n",
    "        # We start by computing the default value that will be used if we'll return a leaf node.\n",
    "        # For classifiers, this will be the most common value in Y.\n",
    "        default_value = self.get_default_value(Y)\n",
    "\n",
    "        # First the two base cases in the recursion: is the training set completely\n",
    "        # homogeneous, or have we reached the maximum depth? Then we need to return a leaf.\n",
    "\n",
    "        # If we have reached the maximum depth, return a leaf with the majority value.\n",
    "        if max_depth == 0:\n",
    "            return DecisionTreeLeaf(default_value)\n",
    "\n",
    "        # If all the instances in the remaining training set have the same output value,\n",
    "        # return a leaf with this value.\n",
    "        if self.is_homogeneous(Y):\n",
    "            return DecisionTreeLeaf(default_value)\n",
    "\n",
    "        # Select the \"most useful\" feature and split threshold. To rank the \"usefulness\" of features,\n",
    "        # we use one of the classification or regression criteria.\n",
    "        # For each feature, we call best_split (defined in a subclass). We then maximize over the features.\n",
    "        n_features = X.shape[1]\n",
    "        _, best_feature, best_threshold = max(self.best_split(X, Y, feature) for feature in range(n_features))\n",
    "        \n",
    "        if best_feature is None:\n",
    "            return DecisionTreeLeaf(default_value)\n",
    "\n",
    "        # Split the training set into subgroups, based on whether the selected feature is greater than\n",
    "        # the threshold or not\n",
    "        X_low, X_high, Y_low, Y_high = self.split_by_feature(X, Y, best_feature, best_threshold)\n",
    "\n",
    "        # Build the subtrees using a recursive call. Each subtree is associated\n",
    "        # with a value of the feature.\n",
    "        low_subtree = self.make_tree(X_low, Y_low, max_depth-1)\n",
    "        high_subtree = self.make_tree(X_high, Y_high, max_depth-1)\n",
    "\n",
    "        if low_subtree == high_subtree:\n",
    "            return low_subtree\n",
    "\n",
    "        # Return a decision tree branch containing the result.\n",
    "        return DecisionTreeBranch(best_feature, best_threshold, low_subtree, high_subtree)\n",
    "    \n",
    "    # Utility method that splits the data into the \"upper\" and \"lower\" part, based on a feature\n",
    "    # and a threshold.\n",
    "    def split_by_feature(self, X, Y, feature, threshold):\n",
    "        low = X[:,feature] <= threshold\n",
    "        high = ~low\n",
    "        return X[low], X[high], Y[low], Y[high]\n",
    "    \n",
    "    # The following three methods need to be implemented by the classification and regression subclasses.\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_default_value(self, Y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def is_homogeneous(self, Y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def best_split(self, X, Y, feature):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class TreeClassifier(DecisionTree, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, max_depth=10, criterion='maj_sum'):\n",
    "        super().__init__(max_depth)\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        # For decision tree classifiers, there are some different ways to measure\n",
    "        # the homogeneity of subsets.\n",
    "        if self.criterion == 'maj_sum':\n",
    "            self.criterion_function = majority_sum_scorer\n",
    "        elif self.criterion == 'info_gain':\n",
    "            self.criterion_function = info_gain_scorer\n",
    "        elif self.criterion == 'gini':\n",
    "            self.criterion_function = gini_scorer\n",
    "        else:\n",
    "            raise Exception(f'Unknown criterion: {self.criterion}')\n",
    "        super().fit(X, Y)\n",
    "        self.classes_ = sorted(set(Y))\n",
    "\n",
    "    # Select a default value that is going to be used if we decide to make a leaf.\n",
    "    # We will select the most common value.\n",
    "    def get_default_value(self, Y):\n",
    "        self.class_distribution = Counter(Y)\n",
    "        return self.class_distribution.most_common(1)[0][0]\n",
    "    \n",
    "    # Checks whether a set of output values is homogeneous. In the classification case, \n",
    "    # this means that all output values are identical.\n",
    "    # We assume that we called get_default_value just before, so that we can access\n",
    "    # the class_distribution attribute. If the class distribution contains just one item,\n",
    "    # this means that the set is homogeneous.\n",
    "    def is_homogeneous(self, Y):\n",
    "        return len(self.class_distribution) == 1\n",
    "        \n",
    "    # Finds the best splitting point for a given feature. We'll keep frequency tables (Counters)\n",
    "    # for the upper and lower parts, and then compute the impurity criterion using these tables.\n",
    "    # In the end, we return a triple consisting of\n",
    "    # - the best score we found, according to the criterion we're using\n",
    "    # - the id of the feature\n",
    "    # - the threshold for the best split\n",
    "    def best_split(self, X, Y, feature):\n",
    "\n",
    "        # Create a list of input-output pairs, where we have sorted\n",
    "        # in ascending order by the input feature we're considering.\n",
    "        sorted_indices = np.argsort(X[:, feature])        \n",
    "        X_sorted = list(X[sorted_indices, feature])\n",
    "        Y_sorted = list(Y[sorted_indices])\n",
    "\n",
    "        n = len(Y)\n",
    "\n",
    "        # The frequency tables corresponding to the parts *before and including*\n",
    "        # and *after* the current element.\n",
    "        low_distr = Counter()\n",
    "        high_distr = Counter(Y)\n",
    "\n",
    "        # Keep track of the best result we've seen so far.\n",
    "        max_score = -np.inf\n",
    "        max_i = None\n",
    "\n",
    "        # Go through all the positions (excluding the last position).\n",
    "        for i in range(0, n-1):\n",
    "\n",
    "            # Input and output at the current position.\n",
    "            x_i = X_sorted[i]\n",
    "            y_i = Y_sorted[i]\n",
    "            \n",
    "            # Update the frequency tables.\n",
    "            low_distr[y_i] += 1\n",
    "            high_distr[y_i] -= 1\n",
    "\n",
    "            # If the input is equal to the input at the next position, we will\n",
    "            # not consider a split here.\n",
    "            #x_next = XY[i+1][0]\n",
    "            x_next = X_sorted[i+1]\n",
    "            if x_i == x_next:\n",
    "                continue\n",
    "\n",
    "            # Compute the homogeneity criterion for a split at this position.\n",
    "            score = self.criterion_function(i+1, low_distr, n-i-1, high_distr)\n",
    "\n",
    "            # If this is the best split, remember it.\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_i = i\n",
    "\n",
    "        # If we didn't find any split (meaning that all inputs are identical), return\n",
    "        # a dummy value.\n",
    "        if max_i is None:\n",
    "            return -np.inf, None, None\n",
    "\n",
    "        # Otherwise, return the best split we found and its score.\n",
    "        split_point = 0.5*(X_sorted[max_i] + X_sorted[max_i+1])\n",
    "        return max_score, feature, split_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_sum_scorer(n_low, low_distr, n_high, high_distr):\n",
    "    maj_sum_low = low_distr.most_common(1)[0][1]\n",
    "    maj_sum_high = high_distr.most_common(1)[0][1]\n",
    "    return maj_sum_low + maj_sum_high\n",
    "    \n",
    "def entropy(distr):\n",
    "    n = sum(distr.values())\n",
    "    ps = [n_i/n for n_i in distr.values()]\n",
    "    return -sum(p*np.log2(p) if p > 0 else 0 for p in ps)\n",
    "\n",
    "def info_gain_scorer(n_low, low_distr, n_high, high_distr):\n",
    "    return -(n_low*entropy(low_distr)+n_high*entropy(high_distr))/(n_low+n_high)\n",
    "\n",
    "def gini_impurity(distr):\n",
    "    n = sum(distr.values())\n",
    "    ps = [n_i/n for n_i in distr.values()]\n",
    "    return 1-sum(p**2 for p in ps)\n",
    "    \n",
    "def gini_scorer(n_low, low_distr, n_high, high_distr):\n",
    "    return -(n_low*gini_impurity(low_distr)+n_high*gini_impurity(high_distr))/(n_low+n_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Testing Decision trees for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_depth : cross validation score\n",
    "\n",
    "2 : array([0.9       , 0.91470588, 0.87352941, 0.87647059, 0.89117647])\n",
    "\n",
    "4 : array([0.91764706, 0.92941176, 0.90588235, 0.88529412, 0.91470588])\n",
    "\n",
    "6: array([0.91470588, 0.92941176, 0.90294118, 0.89117647, 0.91176471])\n",
    "\n",
    "8: array([0.91470588, 0.93235294, 0.89411765, 0.89705882, 0.91176471])\n",
    "\n",
    "10: array([0.90882353, 0.93529412, 0.9       , 0.89117647, 0.91470588])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91470588, 0.92941176, 0.90294118, 0.89117647, 0.91176471])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree classifier\n",
    "model_tree= TreeClassifier(max_depth=6)\n",
    "\n",
    "# Calculating the score for training data\n",
    "cross_val_score(model_tree, Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Accuracy with Tree classifier is ~ 88.5% with max_depth=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Tree classifier for prediction\n",
    "model_tree.fit(Xtrain, Ytrain)\n",
    "Yguess = model_tree.predict(Xtest)\n",
    "\n",
    "# Calculating accuracy score\n",
    "print(accuracy_score(Ytest, Yguess))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. For visual representation max_depth set to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0800)\r\n",
       " -->\r\n",
       "<!-- Pages: 1 -->\r\n",
       "<svg width=\"405pt\" height=\"218pt\"\r\n",
       " viewBox=\"0.00 0.00 405.09 218.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 214)\">\r\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-214 401.09,-214 401.09,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\">\r\n",
       "<title>0</title>\r\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"38.35\" cy=\"-18\" rx=\"38.19\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"38.35\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">suspect</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\">\r\n",
       "<title>1</title>\r\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"143.35\" cy=\"-18\" rx=\"48.99\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"143.35\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">pathologic</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\">\r\n",
       "<title>2</title>\r\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M179.85,-123C179.85,-123 104.85,-123 104.85,-123 98.85,-123 92.85,-117 92.85,-111 92.85,-111 92.85,-99 92.85,-99 92.85,-93 98.85,-87 104.85,-87 104.85,-87 179.85,-87 179.85,-87 185.85,-87 191.85,-93 191.85,-99 191.85,-99 191.85,-111 191.85,-111 191.85,-117 185.85,-123 179.85,-123\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"142.35\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ALTV &gt; 68.5?</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;0 -->\r\n",
       "<g id=\"edge1\" class=\"edge\">\r\n",
       "<title>2&#45;&gt;0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M121.3,-86.8C104.98,-73.46 82.26,-54.89 64.72,-40.56\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.54,-37.52 56.58,-33.9 62.11,-42.94 66.54,-37.52\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"112.35\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;1 -->\r\n",
       "<g id=\"edge2\" class=\"edge\">\r\n",
       "<title>2&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.55,-86.8C142.69,-75.16 142.87,-59.55 143.03,-46.24\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"146.53,-46.22 143.14,-36.18 139.53,-46.13 146.53,-46.22\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"156.85\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\">\r\n",
       "<title>3</title>\r\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"259.35\" cy=\"-18\" rx=\"48.99\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"259.35\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">pathologic</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\">\r\n",
       "<title>4</title>\r\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"361.35\" cy=\"-18\" rx=\"36\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"361.35\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">normal</text>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\">\r\n",
       "<title>5</title>\r\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M298.35,-123C298.35,-123 222.35,-123 222.35,-123 216.35,-123 210.35,-117 210.35,-111 210.35,-111 210.35,-99 210.35,-99 210.35,-93 216.35,-87 222.35,-87 222.35,-87 298.35,-87 298.35,-87 304.35,-87 310.35,-93 310.35,-99 310.35,-99 310.35,-111 310.35,-111 310.35,-117 304.35,-123 298.35,-123\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"260.35\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Mean &gt; 107.5?</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\">\r\n",
       "<title>5&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260.14,-86.8C260.01,-75.16 259.82,-59.55 259.67,-46.24\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.17,-46.13 259.55,-36.18 256.17,-46.22 263.17,-46.13\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"275.35\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\">\r\n",
       "<title>5&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.79,-86.8C296.64,-73.46 318.7,-54.89 335.73,-40.56\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"338.24,-43.02 343.64,-33.9 333.73,-37.66 338.24,-43.02\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"329.85\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\">\r\n",
       "<title>6</title>\r\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M238.85,-210C238.85,-210 161.85,-210 161.85,-210 155.85,-210 149.85,-204 149.85,-198 149.85,-198 149.85,-186 149.85,-186 149.85,-180 155.85,-174 161.85,-174 161.85,-174 238.85,-174 238.85,-174 244.85,-174 250.85,-180 250.85,-186 250.85,-186 250.85,-198 250.85,-198 250.85,-204 244.85,-210 238.85,-210\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"200.35\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MSTV &gt; 0.45?</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;2 -->\r\n",
       "<g id=\"edge5\" class=\"edge\">\r\n",
       "<title>6&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.61,-173.8C180.35,-161.7 169.17,-145.3 159.86,-131.67\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"162.59,-129.46 154.07,-123.18 156.81,-133.41 162.59,-129.46\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"190.35\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;5 -->\r\n",
       "<g id=\"edge6\" class=\"edge\">\r\n",
       "<title>6&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.49,-173.8C221.03,-161.7 232.6,-145.3 242.23,-131.67\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.32,-133.36 248.22,-123.18 239.6,-129.33 245.32,-133.36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"247.85\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x20abf144040>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree1= TreeClassifier(max_depth=2)\n",
    "\n",
    "# Using Tree classifier for prediction with max_depth=2\n",
    "model_tree1.fit(Xtrain, Ytrain)\n",
    "Yguess = model_tree1.predict(Xtest)\n",
    "model_tree1.draw_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
